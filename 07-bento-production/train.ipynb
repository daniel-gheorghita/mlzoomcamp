{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d04e7bea",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d37324f2",
   "metadata": {},
   "source": [
    "### Data preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "49807b73",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = 'https://raw.githubusercontent.com/alexeygrigorev/mlbookcamp-code/master/chapter-06-trees/CreditScoring.csv'\n",
    "df = pd.read_csv(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "28b3fadb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns = df.columns.str.lower()\n",
    "\n",
    "status_values = {\n",
    "    1: 'ok',\n",
    "    2: 'default',\n",
    "    0: 'unk'\n",
    "}\n",
    "\n",
    "df.status = df.status.map(status_values)\n",
    "\n",
    "home_values = {\n",
    "    1: 'rent',\n",
    "    2: 'owner',\n",
    "    3: 'private',\n",
    "    4: 'ignore',\n",
    "    5: 'parents',\n",
    "    6: 'other',\n",
    "    0: 'unk'\n",
    "}\n",
    "\n",
    "df.home = df.home.map(home_values)\n",
    "\n",
    "marital_values = {\n",
    "    1: 'single',\n",
    "    2: 'married',\n",
    "    3: 'widow',\n",
    "    4: 'separated',\n",
    "    5: 'divorced',\n",
    "    0: 'unk'\n",
    "}\n",
    "\n",
    "df.marital = df.marital.map(marital_values)\n",
    "\n",
    "records_values = {\n",
    "    1: 'no',\n",
    "    2: 'yes',\n",
    "    0: 'unk'\n",
    "}\n",
    "\n",
    "df.records = df.records.map(records_values)\n",
    "\n",
    "job_values = {\n",
    "    1: 'fixed',\n",
    "    2: 'partime',\n",
    "    3: 'freelance',\n",
    "    4: 'others',\n",
    "    0: 'unk'\n",
    "}\n",
    "\n",
    "df.job = df.job.map(job_values)\n",
    "\n",
    "for c in ['income', 'assets', 'debt']:\n",
    "    df[c] = df[c].replace(to_replace=99999999, value=np.nan)\n",
    "\n",
    "df = df[df.status != 'unk'].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4fd52ad9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train, df_test = train_test_split(df, test_size=0.2, random_state=11)\n",
    "\n",
    "df_train = df_train.reset_index(drop=True)\n",
    "df_test = df_test.reset_index(drop=True)\n",
    "\n",
    "y_train = (df_train.status == 'default').astype('int').values\n",
    "y_test = (df_test.status == 'default').astype('int').values\n",
    "\n",
    "del df_train['status']\n",
    "del df_test['status']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5fe56815",
   "metadata": {},
   "outputs": [],
   "source": [
    "dv = DictVectorizer(sparse=False)\n",
    "\n",
    "train_dicts = df_train.fillna(0).to_dict(orient='records')\n",
    "X_train = dv.fit_transform(train_dicts)\n",
    "\n",
    "test_dicts = df_test.fillna(0).to_dict(orient='records')\n",
    "X_test = dv.transform(test_dicts)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fb68649",
   "metadata": {},
   "source": [
    "### Random forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a84fa9d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(max_depth=10, min_samples_leaf=3, n_estimators=200,\n",
       "                       random_state=1)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf = RandomForestClassifier(n_estimators=200,\n",
    "                            max_depth=10,\n",
    "                            min_samples_leaf=3,\n",
    "                            random_state=1)\n",
    "rf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05f1bb34",
   "metadata": {},
   "source": [
    "### XGBoost\n",
    "\n",
    "Note:\n",
    "\n",
    "We removed feature names\n",
    "\n",
    "It was \n",
    "\n",
    "```python\n",
    "features = dv.get_feature_names_out()\n",
    "dtrain = xgb.DMatrix(X_train, label=y_train, feature_names=features)\n",
    "```\n",
    "\n",
    "Now it's\n",
    "\n",
    "```python\n",
    "dtrain = xgb.DMatrix(X_train, label=y_train)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "63185f7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "dtrain = xgb.DMatrix(X_train, label=y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d1e284f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_params = {\n",
    "    'eta': 0.1, \n",
    "    'max_depth': 3,\n",
    "    'min_child_weight': 1,\n",
    "\n",
    "    'objective': 'binary:logistic',\n",
    "    'eval_metric': 'auc',\n",
    "\n",
    "    'nthread': 8,\n",
    "    'seed': 1,\n",
    "    'verbosity': 1,\n",
    "}\n",
    "\n",
    "model = xgb.train(xgb_params, dtrain, num_boost_round=175)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23ae12d0",
   "metadata": {},
   "source": [
    "### BentoML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7a230459",
   "metadata": {},
   "outputs": [],
   "source": [
    "import bentoml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0ea2ca87",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Model(tag=\"credit_risk_model:6l3xq4sr7cp57jgr\", path=\"/Users/dg/bentoml/models/credit_risk_model/6l3xq4sr7cp57jgr/\")"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bentoml.xgboost.save_model(\n",
    "    'credit_risk_model',\n",
    "    model,\n",
    "    custom_objects={\n",
    "        'dictVectorizer': dv\n",
    "    })"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5151ea7",
   "metadata": {},
   "source": [
    "Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "492f90ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ed5efc41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"seniority\": 3,\n",
      "  \"home\": \"owner\",\n",
      "  \"time\": 36,\n",
      "  \"age\": 26,\n",
      "  \"marital\": \"single\",\n",
      "  \"records\": \"no\",\n",
      "  \"job\": \"freelance\",\n",
      "  \"expenses\": 35,\n",
      "  \"income\": 0.0,\n",
      "  \"assets\": 60000.0,\n",
      "  \"debt\": 3000.0,\n",
      "  \"amount\": 800,\n",
      "  \"price\": 1000\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "request = df_test.iloc[0].to_dict()\n",
    "print(json.dumps(request, indent=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68868687",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Email from your manager\n",
    "\n",
    "Good morning recruit! It's good to have you here! I have an assignment for you. I have a data scientist that's built a credit risk model in a jupyter notebook. I need you to run the notebook and save the model with BentoML and see how big the model is. If it's greater than a certain size, I'm going to have to request additional resources from our infra team. Please let me know how big it is.\n",
    "\n",
    "Thanks,\n",
    "\n",
    "Mr McManager\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ec2744ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bentoml, version 1.0.7\r\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Question 1\n",
    "\n",
    "    Install BentoML\n",
    "    What's the version of BentoML you installed?\n",
    "    Use --version to find out\n",
    "'''\n",
    "!bentoml --version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f75a3677",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 416\r\n",
      "drwxr-xr-x  5 dg  staff   160B Oct 22 13:01 \u001b[34m.\u001b[m\u001b[m\r\n",
      "drwxr-xr-x  4 dg  staff   128B Oct 22 13:01 \u001b[34m..\u001b[m\u001b[m\r\n",
      "-rw-r--r--  1 dg  staff   716B Oct 22 13:01 custom_objects.pkl\r\n",
      "-rw-r--r--  1 dg  staff   366B Oct 22 13:01 model.yaml\r\n",
      "-rw-r--r--  1 dg  staff   197K Oct 22 13:01 saved_model.ubj\r\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Question 2\n",
    "\n",
    "Run the notebook which contains random forest model from module 6 i.e previous module and save the model with BentoML. To make it easier for you we have prepared this notebook.\n",
    "\n",
    "How big approximately is the saved BentoML model? Size can slightly vary depending on your local development environment. Choose the size closest to your model.\n",
    "\n",
    "    924kb\n",
    "    724kb\n",
    "    114kb\n",
    "    8kb\n",
    "'''\n",
    "!ls -hal /Users/dg/bentoml/models/credit_risk_model/6l3xq4sr7cp57jgr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6266d374",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nAnother email from your manager\\n\\nGreat job recruit! Looks like I won\\'t be having to go back to the procurement team. Thanks for the information.\\n\\nHowever, I just got word from one of the teams that\\'s using one of our ML services and they\\'re saying our service is \"broken\" and their trying to blame our model. I looked at the data their sending and it\\'s completely bogus. I don\\'t want them to send bad data to us and blame us for our models. Could you write a pydantic schema for the data that they should be sending? That way next time it will tell them it\\'s their data that\\'s bad and not our model.\\n\\nThanks,\\n\\nMr McManager\\n'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "Another email from your manager\n",
    "\n",
    "Great job recruit! Looks like I won't be having to go back to the procurement team. Thanks for the information.\n",
    "\n",
    "However, I just got word from one of the teams that's using one of our ML services and they're saying our service is \"broken\" and their trying to blame our model. I looked at the data their sending and it's completely bogus. I don't want them to send bad data to us and blame us for our models. Could you write a pydantic schema for the data that they should be sending? That way next time it will tell them it's their data that's bad and not our model.\n",
    "\n",
    "Thanks,\n",
    "\n",
    "Mr McManager\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0bc7673c",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Question 3\n",
    "\n",
    "Say you have the following data that you're sending to your service:\n",
    "\n",
    "{\n",
    "  \"name\": \"Tim\",\n",
    "  \"age\": 37,\n",
    "  \"country\": \"US\",\n",
    "  \"rating\": 3.14\n",
    "}\n",
    "\n",
    "What would the pydantic class look like? You can name the class UserProfile.\n",
    "'''\n",
    "from pydantic import BaseModel\n",
    "class CreditApplication(BaseModel):\n",
    "    seniority: int\n",
    "    home: str\n",
    "    time: int\n",
    "    age: int\n",
    "    marital: str\n",
    "    records: str\n",
    "    job: str\n",
    "    expenses: int\n",
    "    income: float\n",
    "    assets: float\n",
    "    debt: float\n",
    "    amount: int\n",
    "    price: int"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0c081afc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nEmail from your CEO\\n\\nGood morning! I hear you're the one to go to if I need something done well! We've got a new model that a big client needs deployed ASAP. I need you to build a service with it and test it against the old model and make sure that it performs better, otherwise we're going to lose this client. All our hopes are with you!\\n\\nThanks,\\n\\nCEO of Acme Corp\\n\""
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "Email from your CEO\n",
    "\n",
    "Good morning! I hear you're the one to go to if I need something done well! We've got a new model that a big client needs deployed ASAP. I need you to build a service with it and test it against the old model and make sure that it performs better, otherwise we're going to lose this client. All our hopes are with you!\n",
    "\n",
    "Thanks,\n",
    "\n",
    "CEO of Acme Corp\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "23e504ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[91;40mname\u001b[0m\u001b[97;40m:\u001b[0m\u001b[97;40m \u001b[0m\u001b[40mmlzoomcamp_homework\u001b[0m\u001b[40m                                                       \u001b[0m\r\n",
      "\u001b[91;40mversion\u001b[0m\u001b[97;40m:\u001b[0m\u001b[97;40m \u001b[0m\u001b[40mqtzdz3slg6mwwdu5\u001b[0m\u001b[40m                                                       \u001b[0m\r\n",
      "\u001b[91;40mmodule\u001b[0m\u001b[97;40m:\u001b[0m\u001b[97;40m \u001b[0m\u001b[40mbentoml.sklearn\u001b[0m\u001b[40m                                                         \u001b[0m\r\n",
      "\u001b[91;40mlabels\u001b[0m\u001b[97;40m:\u001b[0m\u001b[97;40m \u001b[0m\u001b[40m{\u001b[0m\u001b[40m}\u001b[0m\u001b[40m                                                                      \u001b[0m\r\n",
      "\u001b[91;40moptions\u001b[0m\u001b[97;40m:\u001b[0m\u001b[97;40m \u001b[0m\u001b[40m{\u001b[0m\u001b[40m}\u001b[0m\u001b[40m                                                                     \u001b[0m\r\n",
      "\u001b[91;40mmetadata\u001b[0m\u001b[97;40m:\u001b[0m\u001b[97;40m \u001b[0m\u001b[40m{\u001b[0m\u001b[40m}\u001b[0m\u001b[40m                                                                    \u001b[0m\r\n",
      "\u001b[91;40mcontext\u001b[0m\u001b[97;40m:\u001b[0m\u001b[40m                                                                        \u001b[0m\r\n",
      "\u001b[97;40m  \u001b[0m\u001b[91;40mframework_name\u001b[0m\u001b[97;40m:\u001b[0m\u001b[97;40m \u001b[0m\u001b[40msklearn\u001b[0m\u001b[40m                                                       \u001b[0m\r\n",
      "\u001b[97;40m  \u001b[0m\u001b[91;40mframework_versions\u001b[0m\u001b[97;40m:\u001b[0m\u001b[40m                                                           \u001b[0m\r\n",
      "\u001b[97;40m    \u001b[0m\u001b[91;40mscikit-learn\u001b[0m\u001b[97;40m:\u001b[0m\u001b[97;40m \u001b[0m\u001b[40m1.1.1\u001b[0m\u001b[40m                                                         \u001b[0m\r\n",
      "\u001b[97;40m  \u001b[0m\u001b[91;40mbentoml_version\u001b[0m\u001b[97;40m:\u001b[0m\u001b[97;40m \u001b[0m\u001b[40m1.0.7\u001b[0m\u001b[40m                                                        \u001b[0m\r\n",
      "\u001b[97;40m  \u001b[0m\u001b[91;40mpython_version\u001b[0m\u001b[97;40m:\u001b[0m\u001b[97;40m \u001b[0m\u001b[40m3.9.12\u001b[0m\u001b[40m                                                        \u001b[0m\r\n",
      "\u001b[91;40msignatures\u001b[0m\u001b[97;40m:\u001b[0m\u001b[40m                                                                     \u001b[0m\r\n",
      "\u001b[97;40m  \u001b[0m\u001b[91;40mpredict\u001b[0m\u001b[97;40m:\u001b[0m\u001b[40m                                                                      \u001b[0m\r\n",
      "\u001b[97;40m    \u001b[0m\u001b[91;40mbatchable\u001b[0m\u001b[97;40m:\u001b[0m\u001b[97;40m \u001b[0m\u001b[40mfalse\u001b[0m\u001b[40m                                                            \u001b[0m\r\n",
      "\u001b[91;40mapi_version\u001b[0m\u001b[97;40m:\u001b[0m\u001b[97;40m \u001b[0m\u001b[40mv1\u001b[0m\u001b[40m                                                                 \u001b[0m\r\n",
      "\u001b[91;40mcreation_time\u001b[0m\u001b[97;40m:\u001b[0m\u001b[97;40m \u001b[0m\u001b[93;40m'\u001b[0m\u001b[93;40m2022-10-13T20:42:14.411084+00:00\u001b[0m\u001b[93;40m'\u001b[0m\u001b[40m                               \u001b[0m\r\n",
      "\u001b[40m                                                                                \u001b[0m\r\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Question 4\n",
    "\n",
    "We've prepared a model for you that you can import using:\n",
    "\n",
    "curl -O https://s3.us-west-2.amazonaws.com/bentoml.com/mlzoomcamp/coolmodel.bentomodel\n",
    "bentoml models import coolmodel.bentomodel\n",
    "\n",
    "What version of scikit-learn was this model trained with?\n",
    "\n",
    "    1.1.1\n",
    "    1.1.2\n",
    "    1.1.3\n",
    "    1.1.4\n",
    "    1.1.5\n",
    "'''\n",
    "#!curl -O https://s3.us-west-2.amazonaws.com/bentoml.com/mlzoomcamp/coolmodel.bentomodel\n",
    "#!bentoml models import coolmodel.bentomodel\n",
    "#!bentoml models get coolmodel.bentomodel\n",
    "!bentoml models get mlzoomcamp_homework"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "9ea02e40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Question 5\n",
    "\n",
    "Create a bento out of this scikit-learn model. The output type for this endpoint should be NumpyNdarray()\n",
    "\n",
    "Send this array to the Bento:\n",
    "\n",
    "[[6.4,3.5,4.5,1.2]]\n",
    "\n",
    "You can use curl or the Swagger UI. What value does it return?\n",
    "\n",
    "    0\n",
    "    1\n",
    "    2\n",
    "    3\n",
    "\n",
    "(Make sure your environment has Scikit-Learn installed)\n",
    "'''\n",
    "!curl -X 'POST' 'http://0.0.0.0:3000/return_output' -H 'accept: application/json' -H 'Content-Type: application/json' -d '[[6.4,3.5,4.5,1.2]]'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "18dc72ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[91;40mname\u001b[0m\u001b[97;40m:\u001b[0m\u001b[97;40m \u001b[0m\u001b[40mmlzoomcamp_homework\u001b[0m\u001b[40m                                                       \u001b[0m\r\n",
      "\u001b[91;40mversion\u001b[0m\u001b[97;40m:\u001b[0m\u001b[97;40m \u001b[0m\u001b[40mjsi67fslz6txydu5\u001b[0m\u001b[40m                                                       \u001b[0m\r\n",
      "\u001b[91;40mmodule\u001b[0m\u001b[97;40m:\u001b[0m\u001b[97;40m \u001b[0m\u001b[40mbentoml.sklearn\u001b[0m\u001b[40m                                                         \u001b[0m\r\n",
      "\u001b[91;40mlabels\u001b[0m\u001b[97;40m:\u001b[0m\u001b[97;40m \u001b[0m\u001b[40m{\u001b[0m\u001b[40m}\u001b[0m\u001b[40m                                                                      \u001b[0m\r\n",
      "\u001b[91;40moptions\u001b[0m\u001b[97;40m:\u001b[0m\u001b[97;40m \u001b[0m\u001b[40m{\u001b[0m\u001b[40m}\u001b[0m\u001b[40m                                                                     \u001b[0m\r\n",
      "\u001b[91;40mmetadata\u001b[0m\u001b[97;40m:\u001b[0m\u001b[97;40m \u001b[0m\u001b[40m{\u001b[0m\u001b[40m}\u001b[0m\u001b[40m                                                                    \u001b[0m\r\n",
      "\u001b[91;40mcontext\u001b[0m\u001b[97;40m:\u001b[0m\u001b[40m                                                                        \u001b[0m\r\n",
      "\u001b[97;40m  \u001b[0m\u001b[91;40mframework_name\u001b[0m\u001b[97;40m:\u001b[0m\u001b[97;40m \u001b[0m\u001b[40msklearn\u001b[0m\u001b[40m                                                       \u001b[0m\r\n",
      "\u001b[97;40m  \u001b[0m\u001b[91;40mframework_versions\u001b[0m\u001b[97;40m:\u001b[0m\u001b[40m                                                           \u001b[0m\r\n",
      "\u001b[97;40m    \u001b[0m\u001b[91;40mscikit-learn\u001b[0m\u001b[97;40m:\u001b[0m\u001b[97;40m \u001b[0m\u001b[40m1.1.1\u001b[0m\u001b[40m                                                         \u001b[0m\r\n",
      "\u001b[97;40m  \u001b[0m\u001b[91;40mbentoml_version\u001b[0m\u001b[97;40m:\u001b[0m\u001b[97;40m \u001b[0m\u001b[40m1.0.7\u001b[0m\u001b[40m                                                        \u001b[0m\r\n",
      "\u001b[97;40m  \u001b[0m\u001b[91;40mpython_version\u001b[0m\u001b[97;40m:\u001b[0m\u001b[97;40m \u001b[0m\u001b[40m3.9.12\u001b[0m\u001b[40m                                                        \u001b[0m\r\n",
      "\u001b[91;40msignatures\u001b[0m\u001b[97;40m:\u001b[0m\u001b[40m                                                                     \u001b[0m\r\n",
      "\u001b[97;40m  \u001b[0m\u001b[91;40mpredict\u001b[0m\u001b[97;40m:\u001b[0m\u001b[40m                                                                      \u001b[0m\r\n",
      "\u001b[97;40m    \u001b[0m\u001b[91;40mbatchable\u001b[0m\u001b[97;40m:\u001b[0m\u001b[97;40m \u001b[0m\u001b[40mtrue\u001b[0m\u001b[40m                                                             \u001b[0m\r\n",
      "\u001b[97;40m    \u001b[0m\u001b[91;40mbatch_dim\u001b[0m\u001b[97;40m:\u001b[0m\u001b[40m                                                                  \u001b[0m\r\n",
      "\u001b[97;40m    \u001b[0m\u001b[40m-\u001b[0m\u001b[97;40m \u001b[0m\u001b[40m0\u001b[0m\u001b[40m                                                                         \u001b[0m\r\n",
      "\u001b[97;40m    \u001b[0m\u001b[40m-\u001b[0m\u001b[97;40m \u001b[0m\u001b[40m0\u001b[0m\u001b[40m                                                                         \u001b[0m\r\n",
      "\u001b[91;40mapi_version\u001b[0m\u001b[97;40m:\u001b[0m\u001b[97;40m \u001b[0m\u001b[40mv1\u001b[0m\u001b[40m                                                                 \u001b[0m\r\n",
      "\u001b[91;40mcreation_time\u001b[0m\u001b[97;40m:\u001b[0m\u001b[97;40m \u001b[0m\u001b[93;40m'\u001b[0m\u001b[93;40m2022-10-14T14:48:43.330446+00:00\u001b[0m\u001b[93;40m'\u001b[0m\u001b[40m                               \u001b[0m\r\n",
      "\u001b[40m                                                                                \u001b[0m\r\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Question 6\n",
    "\n",
    "Ensure to serve your bento with --production for this question\n",
    "\n",
    "Install locust using:\n",
    "\n",
    "pip install locust\n",
    "\n",
    "Use the following locust file: locustfile.py\n",
    "\n",
    "Ensure that it is pointed at your bento's endpoint (In case you didn't name your endpoint \"classify\")\n",
    "\n",
    "Configure 100 users with ramp time of 10 users per second. Click \"Start Swarming\" and ensure that it is working.\n",
    "\n",
    "Now download a second model with this command:\n",
    "\n",
    "curl -O https://s3.us-west-2.amazonaws.com/bentoml.com/mlzoomcamp/coolmodel2.bentomodel\n",
    "\n",
    "Or you can download with this link as well: https://s3.us-west-2.amazonaws.com/bentoml.com/mlzoomcamp/coolmodel2.bentomodel\n",
    "\n",
    "Now import the model:\n",
    "\n",
    "bentoml models import coolmodel2.bentomodel\n",
    "\n",
    "Update your bento's runner tag and test with both models. Which model allows more traffic (more throughput) as you ramp up the traffic?\n",
    "\n",
    "Hint 1: Remember to turn off and turn on your bento service between changing the model tag. Use Ctl-C to close the service in between trials.\n",
    "\n",
    "Hint 2: Increase the number of concurrent users to see which one has higher throughput\n",
    "\n",
    "Which model has better performance at higher volumes?\n",
    "\n",
    "    The first model\n",
    "    The second model <- this one!\n",
    "'''\n",
    "\n",
    "#!locust -H http://localhost:3000\n",
    "#!curl -O https://s3.us-west-2.amazonaws.com/bentoml.com/mlzoomcamp/coolmodel2.bentomodel\n",
    "#!bentoml models import coolmodel2.bentomodel\n",
    "!bentoml models get mlzoomcamp_homework"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "174e7652",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nEmail from marketing\\n\\nHello ML person! I hope this email finds you well. I've heard there's this cool new ML model called Stable Diffusion. I hear if you give it a description of a picture it will generate an image. We need a new company logo and I want it to be fierce but also cool, think you could help out?\\n\\nThanks,\\n\\nMike Marketer\\n\""
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "Email from marketing\n",
    "\n",
    "Hello ML person! I hope this email finds you well. I've heard there's this cool new ML model called Stable Diffusion. I hear if you give it a description of a picture it will generate an image. We need a new company logo and I want it to be fierce but also cool, think you could help out?\n",
    "\n",
    "Thanks,\n",
    "\n",
    "Mike Marketer\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "047c56a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nQuestion 7 (optional)\\n\\nGo to this Bento deployment of Stable Diffusion: http://54.176.205.174/ (or deploy it yourself)\\n\\nUse the txt2image endpoint and update the prompt to: \"A cartoon dragon with sunglasses\". Don\\'t change the seed, it should be 0 by default\\n\\nWhat is the resulting image?\\n#1\\n\\n#2\\n\\n#3\\n\\n#4\\n'"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "Question 7 (optional)\n",
    "\n",
    "Go to this Bento deployment of Stable Diffusion: http://54.176.205.174/ (or deploy it yourself)\n",
    "\n",
    "Use the txt2image endpoint and update the prompt to: \"A cartoon dragon with sunglasses\". Don't change the seed, it should be 0 by default\n",
    "\n",
    "What is the resulting image?\n",
    "#1\n",
    "\n",
    "#2\n",
    "\n",
    "#3\n",
    "\n",
    "#4\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d791c04a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
